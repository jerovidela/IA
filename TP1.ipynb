{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUX78DM7n9T"
      },
      "source": [
        "# Temas Tratados en el Trabajo Práctico 1\n",
        "\n",
        "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
        "\n",
        "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
        "\n",
        "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
        "\n",
        "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
        "\n",
        "* Caracterización del Entorno de Trabajo.\n",
        "\n",
        "# Anotaciones\n",
        "\n",
        "\"Acordarse de la definición de agente\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Teóricos\n",
        "\n",
        "1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inteligencia Natural: Es la capacidad de los seres vivos para detectar su entorno, aprender de la experiencia y tomar deciciones. Es una inteligencia que no tiene algo sintetico, no es creada artificialmente. Un ejemplo puede ser un perro detectando un tipo de patron y responder a éste. No es algo presente únicamente en los humanos.\n",
        "\n",
        "Inteligencia Artificial: Es la capacidad de sistemas creados por el ser humano para imitar ciertas funciones de la inteligencia natural, como razonar, aprender o resolver problemas. Funciona a partir de algoritmos y reglas programadas, y su naturaleza es completamente sintética.\n",
        "\n",
        "Agente: Puede hacer algo en el mundo. Es una entidad que dispone de algun modo de leer la información útil y realizar cambios en el mundo para realizar su objetivo. En el caso de agentes artificiales, se diseñan para objetivos específicos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "2. ¿Qué es un agente racional?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un agente racional es, básicamente, un agente que siempre elige la acción que cree que maximizará su rendimiento, según la información que tiene disponible en ese momento y su modelo del entorno.\n",
        "\n",
        "Percibe su entorno a través de sensores.\n",
        "Decide qué hacer basándose en sus percepciones, conocimientos y objetivos.\n",
        "Actúa buscando obtener el mejor resultado posible según una medida de rendimiento predefinida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. ¿Un agente es siempre una computadora?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No necesariamente.EL término agente se utiliza para cualquier entidad que percibe su entorno, toma decisiones basadas en esto y actúa sobre su entorno. Por ejemplo, el humano tambien puede ser considerado un agente racional, cualquier sistema que pueda tomar variables y generar modificaciones en función de esto puede ser considerado un agente.\n",
        "Un ejemplo de un agente que no es una computadora ni tampoco un agente natural puede ser el sistema del apaga velas.Sería un agente simple, que percibe un estímulo y actúa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Defina Omnisciencia, Aprendizaje y Autonomía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Omniciencia: Capacidad de conocer absolutamente toda la información sobre el estado (Actual, pasado y futuro) del entorno. Ningún agente, ni humano ni artificial, puede ser realmente omniciente. Se puede preparar algo increiblemente completo y cercano a la realidad en contextos limitados, pero no omniciente.\n",
        "\n",
        "Aprendizaje: Capacidad de un agente de mejorar su rendimiento a lo largo del tiempo, lo que permite que se vayan mejorando los parametros internos en base a la experiencia y a los resultados obtenidos.\n",
        "\n",
        "Autonomía: Grado en que un agente puede operar y tomar decisiones por sí mismo, sin intervención humana directa. No necesita supervicion para desarrollar correctamente su tarea en cuanto al rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agente reactivo simple\n",
        "\n",
        "    Estructura: Actúa directamente según la percepción actual, sin considerar el historial ni predecir consecuencias futuras Tienen inteligencia limitada y necesitan que el mundo sea totalmente observable para tomar la decisión correcta\n",
        "    Ejemplo: Una pava eléctrica que se apaga cuando el agua hierve; una puerta automática que se abre al detectar movimiento.\n",
        "\n",
        "Agente basado en modelos\n",
        "\n",
        "    Estructura: Incorpora un modelo del entorno para actualizar su estado interno y mejorar la calidad de las acciones. \n",
        "    Ejemplo: Un termostato inteligente que ajusta la calefacción según la temperatura actual y un modelo del tiempo esperado; una cámara que ajusta la iluminación en función del color detectado.\n",
        "\n",
        "Agente basado en objetivos\n",
        "\n",
        "    Estructura: Usa el modelo del mundo y un objetivo deseado para decidir las acciones que lo acercarán a ese estado. El agente no se limita a reaccionar a estímulos inmediatos, sino queproyecta el impacto de sus acciones hasta alcanzar el objetivo.\n",
        "    Ejemplo: Un sistema de delivery que planifica rutas para cumplir con la entrega; Google Maps buscando el camino más corto.\n",
        "\n",
        "Agente basado en utilidad\n",
        "\n",
        "    Estructura: Elige acciones no solo para alcanzar un objetivo, sino optimizando según una función de utilidad que refleja preferencias.\n",
        "    Ejemplo: Un planificador de rutas que elige el camino más cómodo, evitando semáforos o tráfico, aunque no sea el más corto.\n",
        "\n",
        "Agente que aprende\n",
        "\n",
        "    Estructura: Ajusta y mejora su comportamiento con la experiencia, modificando su modelo, objetivos o función de utilidad.\n",
        "    Ejemplo: Un robot aspiradora que recuerda el plano de una casa para limpiar más rápido en cada pasada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Para los siguientes entornos de trabajo indique sus **propiedades**:\n",
        "\n",
        "        a. Una partida de ajedrez.\n",
        "                Totalmente observable\n",
        "                Estocastico\n",
        "                Episodico\n",
        "                Entorno: Estatico\n",
        "                Discreto\n",
        "                Multiagente\n",
        "\n",
        "\n",
        "\n",
        "        b. Un partido de baloncesto.\n",
        "                Parcialmente observable\n",
        "                Estocastico\n",
        "                Secuencial\n",
        "                Entorno: Dinámico\n",
        "                Discreto y continuo\n",
        "                Multiagente\n",
        "\n",
        "        c. El juego Pacman.\n",
        "                Totalmente observable\n",
        "                Estocastico\n",
        "                Secuencial\n",
        "                Entorno: Dinámico\n",
        "                Discreto\n",
        "                Multiagente\n",
        "\n",
        "        d. El truco.\n",
        "                Parcialmente observable\n",
        "                Estocastico\n",
        "                Secuencial\n",
        "                Entorno: Estático\n",
        "                Discreto\n",
        "                Multiagente\n",
        "\n",
        "        e. Las damas.\n",
        "                Totalmente observable\n",
        "                Determinista\n",
        "                Secuencial\n",
        "                Entorno: Estático\n",
        "                Discreto\n",
        "                Multiagente\n",
        "\n",
        "        f. El juego tres en raya.\n",
        "                Totalmente observable\n",
        "                Determinista\n",
        "                Secuencial\n",
        "                Entorno: Estático\n",
        "                Discreto\n",
        "                Multiagente\n",
        "\n",
        "        g. Un jugador de Pokémon Go.\n",
        "                Parcialmente observable\n",
        "                Estocastico\n",
        "                Secuencial\n",
        "                Entorno: Dinámico\n",
        "                Discreto y continuo\n",
        "                Multiagente\n",
        "\n",
        "        h. Un robot explorador autónomo de Marte.\n",
        "                Parcialmente observable\n",
        "                Estocástico\n",
        "                Secuencial\n",
        "                Dinámico\n",
        "                Discreto y contínuo\n",
        "                Monoagente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Memotecnica. Si ejecuto una vez y da un resultado y despues da algo igual (a igual entrada) Determinista\n",
        "Si puedo cambiar en funcion de lo que pase: Dinamico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
        "\n",
        "        a. Crucigrama.\n",
        "                Rendimiento: Completar todas las palabras en el menor tiempo posible.\n",
        "                Entorno: Tablero con celdas con letras y espacios en blando.\n",
        "                Actuadores: Lápiz o lapicera.\n",
        "                Sensores: Vista, reconocimiento de patrones y letras.\n",
        "\n",
        "        b. Taxi circulando.\n",
        "                Rendimiento: Seguridad, rapidez y minimizar distancias.\n",
        "                Entorno: Calles, peatones, clientes, semáforos, condiciones climáticas.\n",
        "                Actuadores: Volante(dirección), frenos, acelerador, luces, bocina. \n",
        "                Sensores: GPS(o mapa), velocimetro, taxímetro.\n",
        "\n",
        "        c. Robot clasificador de piezas.\n",
        "                Rendimiento: Seleccionar y clasificar piezas correctamente segun las cualidades seteadas con la mayor confiabilidad posible.\n",
        "                Entorno: Cinta transportadora donde se encuentran las piezas.\n",
        "                Actuadores: Brazo robótico, pinza de agarre.\n",
        "                Sensores: Cámara de visión artificial, sensor de color, detectores de posición."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Prácticos\n",
        "\n",
        "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
        "\n",
        "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
        "\n",
        "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
        "\n",
        "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pygame\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "#Tener en cuenta que para poder correr el juego es necesario instalar la librería pygame y la librería numpy\n",
        "\n",
        "pygame.init()\n",
        "height, width = 500, 500\n",
        "\n",
        "screen = pygame.display.set_mode((height, width))\n",
        "\n",
        "bg = 25, 25, 25\n",
        "screen.fill(bg)\n",
        "nxC, nyC = 25, 25\n",
        "dimCW = width / nxC\n",
        "dimCH = height / nyC\n",
        "gameState = np.zeros((nxC,nyC))\n",
        "for y in range(0, nxC):\n",
        "    for x in range(0, nyC):\n",
        "             gameState[x, y] = random.randint(0,1)\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "    newGameState = np.copy(gameState)\n",
        "    screen.fill(bg)\n",
        "    time.sleep(0.1)\n",
        "    for y in range(0, nxC):\n",
        "        for x in range(0, nyC):\n",
        "            n_neigh = gameState[(x-1) % nxC, (y-1) % nyC] + \\\n",
        "                    gameState[(x) % nxC, (y-1) % nyC] + \\\n",
        "                    gameState[(x+1) % nxC, (y-1) % nyC] + \\\n",
        "                    gameState[(x-1) % nxC, (y) % nyC] + \\\n",
        "                    gameState[(x+1) % nxC, (y) % nyC] + \\\n",
        "                    gameState[(x-1) % nxC, (y+1) % nyC] + \\\n",
        "                    gameState[(x) % nxC, (y+1) % nyC] + \\\n",
        "                    gameState[(x+1) % nxC, (y+1) % nyC]\n",
        "            if gameState[x, y] == 0 and n_neigh ==3:\n",
        "                newGameState[x,y]=1\n",
        "            elif gameState[x, y] == 1 and (n_neigh < 2 or n_neigh > 3):\n",
        "                newGameState[x, y] = 0\n",
        "            poly = [((x) * dimCW, y * dimCH),\n",
        "                    ((x+1) * dimCW, y * dimCH),\n",
        "                    ((x+1) * dimCW, (y+1) * dimCH),\n",
        "                    ((x) * dimCW, (y+1) * dimCH)]\n",
        "            if newGameState[x, y] == 0:\n",
        "                pygame.draw.polygon(screen, (128, 128, 128), poly, 1)\n",
        "            else:\n",
        "                pygame.draw.polygon(screen, (255, 255, 255), poly, 0)\n",
        "    gameState = np.copy(newGameState)\n",
        "    pygame.display.flip()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcAF__NmgG5"
      },
      "source": [
        "# Bibliografía\n",
        "\n",
        "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
        "\n",
        "[Poole, D. & Mackworth, A. (2023) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (3a Ed.) Vancouver, Canada](https://artint.info/3e/html/ArtInt3e.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
